import logging

def log_airflow_context(**kwargs):
    """
    Logs useful Airflow context variables from kwargs.
    Can be reused in multiple tasks for debugging and observability.
    Also logs Dataflow job info if present in XComs.
    """
    log = logging.getLogger("airflow.task")

    # Basic Airflow context
    log.info("ðŸ”¹ DAG ID: %s", kwargs["dag"].dag_id)
    log.info("ðŸ”¹ Task ID: %s", kwargs["task"].task_id)
    log.info("ðŸ”¹ Run ID: %s", kwargs["dag_run"].run_id)
    log.info("ðŸ”¹ Execution Date (datetime): %s", kwargs["execution_date"])
    log.info("ðŸ”¹ DS (date string): %s", kwargs["ds"])
    log.info("ðŸ”¹ Next Execution Date: %s", kwargs.get("next_execution_date"))
    log.info("ðŸ”¹ Previous Execution Date: %s", kwargs.get("prev_execution_date"))
    log.info("ðŸ”¹ Params: %s", kwargs.get("params", {}))

    # Task instance info
    ti = kwargs["ti"]
    log.info("ðŸ”¹ Try Number: %s", ti.try_number)
    log.info("ðŸ”¹ Task State: %s", ti.state)

    # Check if this task launched a Dataflow Flex Template
    job_info = ti.xcom_pull(task_ids=ti.task_id)
    if job_info and isinstance(job_info, dict):
        job_id = job_info.get("job", {}).get("id")
        project = job_info.get("job", {}).get("projectId")
        region = job_info.get("job", {}).get("location")

        if job_id:
            log.info("ðŸš€ Dataflow Job launched:")
            log.info("   â€¢ Job ID: %s", job_id)
            log.info("   â€¢ Project: %s", project)
            log.info("   â€¢ Region: %s", region)
            log.info("   â€¢ Console URL: https://console.cloud.google.com/dataflow/jobs/%s/%s?project=%s",
                     region, job_id, project)
